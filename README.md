# Mobile-RetinaNet : A Computationally Efficient DeepNet for Retinal Fundus Image Segmentation for Use in Low-resource Settings

## Abstract:
Retinal fundus photography is used by physicians to detect and track different eye diseases such as glaucoma and diabetic retinopathy (DR). This work presents a computer-aided automatic segmentation model for the retinal blood vessels and optic disc in retinal fundus images. Accurate automatic detection of these image features will reduce the manual effort while producing consistent results in clinical settings instantaneously. We  propose a novel and efficient deep learning architecture for retinal fundus image segmentation for retinal vessels and optic discs. The efficient use of bottleneck residual blocks on the U-Net like encoder-decoder convolutional neural network (CNN) architecture requires a significantly lesser number of floating-point operations (FLOPs) to achieve the desired accuracy. The network architecture allows building a much deeper network without impacting the computational complexity. The model has been trained and tested on two publicly available retinal datasets, digital retinal images for vessel extraction (DRIVE) and child heart and health study in England (CHASE). The model's performance is compared with the prior art using widely used accuracy, sensitivity, specificity, and the area under the curve (AUC). To measure the model's computational efficiency, we use the platform-independent FLOPs count. This model achieved close to state-of-the-art performance with much higher computational efficiency. While our base model achieved the AUC score within 2\% compared to the SA-UNet, our model requires almost half parameters and is 4.5 times more efficient.

## Model:
![Mobile_RetinaNet](https://github.com/rkarmaka/Mobile-RetinaNet/blob/figs/model_arch_model.png?raw=true)

## Dataset:
Google Drive <a href="https://drive.google.com/drive/folders/1s2N1RVwF_k9-ZLEXioKQkNGso4ocTzXc?usp=sharing">

## Conclusion:
This work proposed Mobile-RetinaNet, a highly efficient retinal vessel segmentation network for use in low-resource devices. Mobile-RetinaNet was trained and tested for its performance on two publicly available datasets, DRIVE and CHASE. We used sensitivity, specificity, accuracy, the area under the curve, and dice score/F1 score. We used parameters count, FLOPs requirements, epochs to converge, and disk space for storage as efficiency metrics. On both datasets, Mobile-RetinaNet achieved the highest sensitivity while being very efficient. It requires almost 2.5 times fewer parameters, nearly half disk space, and 4.5 times fewer FLOPs counts than the current state-of-the-art. In the training phase, the model converges quickly.
Quick and automatic detection of blood vessels and optic disc can help with the diagnosis for diabetic retinopathy and Glaucoma from retinal fundus images when resources are limited. As diabetic retinopathy causes the shrinkage of retinal blood,  through automatic segmentation of the blood vessels, we have an objective means to track identify the presence of diabetic retinopathy. For Glaucoma, in addition to the segmentation of optical disc, we also need segmentation of the optic cup.  In our future work, as  labelled data becomes available, we intend to extent the work to test the the model's performance in segmentation of optic cup and measure Glaucoma.
